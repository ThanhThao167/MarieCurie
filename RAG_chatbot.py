# RAG_chatbot.py
# FastAPI backend cho Chatbot Tuy·ªÉn sinh 10 ‚Äì THPT Marie Curie (Cloud-ready)

import os
import csv
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime, timedelta

import pandas as pd
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from deep_translator import GoogleTranslator
from dotenv import load_dotenv
from fastapi import FastAPI, Request, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel
from openai import OpenAI

# =========================
# 0) ENV & Logging
# =========================
load_dotenv()
logger = logging.getLogger("RAG_Chatbot")
logging.basicConfig(level=logging.INFO)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    logger.warning("‚ö†Ô∏è OPENAI_API_KEY ch∆∞a ƒë∆∞·ª£c ƒë·∫∑t ‚Äì fallback GPT s·∫Ω l·ªói.")
client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu CSV (c√≥ th·ªÉ ƒë·ªïi qua ENV: DATA_DIR), m·∫∑c ƒë·ªãnh l√† root
DATA_DIR = Path(os.getenv("DATA_DIR", "."))
DATA_DIR.mkdir(parents=True, exist_ok=True)
CHAT_CSV = DATA_DIR / "chat_history.csv"
FEED_CSV = DATA_DIR / "feedback.csv"
KB_CSV = DATA_DIR / "MC_chatbot.csv"   # ngu·ªìn tri th·ª©c

# =========================
# 1) App & CORS
# =========================
app = FastAPI(title="Marie Curie RAG Chatbot API")
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"], allow_credentials=True, allow_methods=["*"], allow_headers=["*"]
)

# =========================
# 2) Pydantic payload
# =========================
class ChatPayload(BaseModel):
    session_id: str
    messages: List[Dict[str, Any]]  # [{"role":"user/assistant","content":"..."}]

# =========================
# 3) Load Knowledge Base + FAISS
# =========================
def _load_kb(kb_path: Path) -> tuple[list[str], list[str]]:
    if not kb_path.exists():
        logger.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y {kb_path}. RAG s·∫Ω ho·∫°t ƒë·ªông h·∫°n ch·∫ø.")
        return [], []
    df = pd.read_csv(kb_path, encoding="utf-8")
    # b·∫Øt bu·ªôc c√≥ 2 c·ªôt 'cauhoi' v√† 'cautraloi'
    if not {"cauhoi", "cautraloi"}.issubset(df.columns):
        raise RuntimeError("File MC_chatbot.csv c·∫ßn c√≥ c·ªôt 'cauhoi' v√† 'cautraloi'.")
    return df["cauhoi"].tolist(), df["cautraloi"].tolist()

questions, answers = _load_kb(KB_CSV)

# Model & FAISS index
model = SentenceTransformer("all-MiniLM-L6-v2")
if questions:
    embeddings = model.encode(questions, convert_to_numpy=True)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
else:
    embeddings = None
    index = None

# =========================
# 4) CSV helpers
# =========================
def _append_csv(path: Path, fieldnames: list[str], row: dict):
    path.parent.mkdir(parents=True, exist_ok=True)
    file_exists = path.exists()
    with path.open("a", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=fieldnames)
        if not file_exists:
            w.writeheader()
        w.writerow({k: row.get(k, "") for k in fieldnames})

def _read_csv_dicts(path: Path) -> list[dict]:
    if not path.exists():
        return []
    with path.open("r", newline="", encoding="utf-8") as f:
        return list(csv.DictReader(f))

def save_chat(session_id: str, role: str, content: str):
    _append_csv(
        CHAT_CSV,
        ["timestamp", "session_id", "role", "content"],
        {"timestamp": datetime.utcnow().isoformat(), "session_id": session_id, "role": role, "content": content},
    )

def save_feedback(session_id: str, question: str, answer: str, rating: str):
    _append_csv(
        FEED_CSV,
        ["timestamp", "session_id", "question", "answer", "rating"],
        {
            "timestamp": datetime.utcnow().isoformat(),
            "session_id": session_id,
            "question": question,
            "answer": answer,
            "rating": rating,
        },
    )

# =========================
# 5) Ti·ªán √≠ch ng√¥n ng·ªØ & ng√†y th√°ng
# =========================
def detect_language(text: str) -> str:
    en_keywords = ["what", "how", "where", "when", "school", "admission", "who", "principal", "gold", "weather", "tomorrow"]
    return "en" if any(w in text.lower() for w in en_keywords) else "vi"

DAY_MAP = {
    "Monday": "Hai", "Tuesday": "Ba", "Wednesday": "T∆∞",
    "Thursday": "NƒÉm", "Friday": "S√°u", "Saturday": "B·∫£y", "Sunday": "Ch·ªß Nh·∫≠t"
}

def get_date_info(days_offset=0) -> str:
    now = datetime.now() + timedelta(days=days_offset)
    day_vi = DAY_MAP.get(now.strftime("%A"), now.strftime("%A"))
    prefix = "H√¥m nay" if days_offset == 0 else "Ng√†y mai" if days_offset == 1 else "H√¥m qua" if days_offset == -1 else f"Ng√†y {now.day} th√°ng {now.month} nƒÉm {now.year}"
    return f"{prefix} l√† th·ª© {day_vi}, ng√†y {now.day} th√°ng {now.month} nƒÉm {now.year}."

# =========================
# 6) RAG ‚Äì Retrieve
# =========================
def retrieve_context(query: str, top_k: int = 3) -> tuple[list[str], float]:
    if index is None or embeddings is None or not questions:
        return [], 0.0
    q_embed = model.encode([query], convert_to_numpy=True)
    D, I = index.search(q_embed, top_k)
    # l·ªçc c√°c k·∫øt qu·∫£ qu√° xa (L2 nh·ªè h∆°n ng∆∞·ª°ng th√¨ g·∫ßn). Ng∆∞·ª°ng ·ªü ƒë√¢y kh√° n·ªõi.
    contexts = [
        f"Q: {questions[i]}\nA: {answers[i]}\n"
        for idx, i in enumerate(I[0])
        if i >= 0 and D[0][idx] < 1.0
    ]
    # similarity ‚Äúgi·∫£ l·∫≠p‚Äù t·ª´ L2 distance ƒë·ªÉ gi·ªØ t∆∞∆°ng th√≠ch
    best_sim = float(max(0.0, 1.0 - float(D[0][0]))) if len(D[0]) > 0 else 0.0
    return contexts, best_sim

# =========================
# 7) API
# =========================
@app.get("/health")
def health():
    return {"status": "ok"}

@app.post("/chat")
async def chat_handler(payload: ChatPayload, request: Request):
    """X·ª≠ l√Ω h·ªôi tho·∫°i: RAG -> rule-based ng√†y th√°ng -> GPT fallback."""
    user_input = payload.messages[-1]["content"]
    session_id = payload.session_id
    user_lang = detect_language(user_input)

    # D·ªãch sang ti·∫øng Vi·ªát n·∫øu ng∆∞·ªùi d√πng n√≥i ti·∫øng Anh (ƒë·ªÉ retrieve t·ªët h∆°n)
    try:
        translated_input = GoogleTranslator(source="auto", target="vi").translate(user_input) if user_lang == "en" else user_input
    except Exception:
        translated_input = user_input

    # Retrieve tri th·ª©c
    context_chunks, similarity = retrieve_context(translated_input)
    logger.info(f"üîç FAISS similarity = {similarity:.2f}")

    # L∆∞u c√¢u c·ªßa user
    save_chat(session_id, "user", user_input)

    lower_input = translated_input.lower()
    # X·ª≠ l√Ω ƒë·∫∑c bi·ªát v·ªÅ ng√†y th√°ng
    if "h√¥m nay" in lower_input or "hi·ªán t·∫°i" in lower_input or "th·ª© m·∫•y h√¥m nay" in lower_input:
        reply = get_date_info(0)
    elif "ng√†y mai" in lower_input or "mai l√† th·ª© m·∫•y" in lower_input:
        reply = get_date_info(1)
    elif "h√¥m qua" in lower_input or "qua l√† th·ª© m·∫•y" in lower_input:
        reply = get_date_info(-1)
    else:
        reply = None

    if reply is not None:
        if user_lang == "en":
            try:
                reply = GoogleTranslator(source="vi", target="en").translate(reply)
            except Exception:
                pass
        save_chat(session_id, "assistant", reply)
        return {"response": reply, "source": "real_time", "similarity": round(float(similarity), 2)}

    # N·∫øu similarity ƒë·ªß cao, d√πng c√¢u tr·∫£ l·ªùi KB
    if similarity >= 0.85 and context_chunks:
        top_answer = context_chunks[0].split("A:", 1)[-1].strip()
        if user_lang == "en":
            try:
                top_answer = GoogleTranslator(source="vi", target="en").translate(top_answer)
            except Exception:
                pass
        save_chat(session_id, "assistant", top_answer)
        return {"response": top_answer, "source": "knowledge_base", "similarity": round(float(similarity), 2)}

    # Fallback GPT
    current_date_info = get_date_info(0)
    prompt = (
        f"{current_date_info}\n\n"
        "B·∫°n l√† tr·ª£ l√Ω AI th√¢n thi·ªán, ch√≠nh x√°c. Tr·∫£ l·ªùi b·∫±ng c√πng ng√¥n ng·ªØ v·ªõi ng∆∞·ªùi d√πng "
        "(Anh/Vi·ªát). N·∫øu c√≥ ng·ªØ c·∫£nh n·ªôi b·ªô, ∆∞u ti√™n d√πng.\n\n"
        + ("\n".join(context_chunks) if context_chunks else "")
    )
    messages = [{"role": "system", "content": prompt}] + payload.messages[-3:]

    try:
        if client is None:
            raise RuntimeError("OPENAI_API_KEY not set")
        completion = client.chat.completions.create(model="gpt-4o-mini", messages=messages)
        gpt_reply = completion.choices[0].message.content
    except Exception as e:
        logger.error(f"‚ùå GPT error: {e}")
        gpt_reply = "Xin l·ªói, h·ªá th·ªëng ƒëang g·∫∑p s·ª± c·ªë khi t·∫°o c√¢u tr·∫£ l·ªùi." if user_lang == "vi" else "Sorry, the system is experiencing an issue generating the response."

    save_chat(session_id, "assistant", gpt_reply)
    return {"response": gpt_reply, "source": "rag_gpt", "similarity": round(float(similarity), 2)}

# -------------------------
# 8) Feedback
# -------------------------
@app.post("/feedback")
async def feedback(
    session_id: str = Form(...),
    question: str = Form(...),
    answer: str = Form(...),
    rating: str = Form(...)
):
    save_feedback(session_id, question, answer, rating)
    return {"status": "ok", "message": "ƒê√£ ghi nh·∫≠n ph·∫£n h·ªìi."}

# -------------------------
# 9) Endpoints d·ªØ li·ªáu cho trang Qu·∫£n tr·ªã
# -------------------------
@app.get("/history")
def get_history():
    """Tr·∫£ JSON l·ªãch s·ª≠ chat."""
    return JSONResponse(_read_csv_dicts(CHAT_CSV))

@app.get("/feedbacks")
def get_feedbacks():
    """Tr·∫£ JSON danh s√°ch feedback."""
    return JSONResponse(_read_csv_dicts(FEED_CSV))

@app.get("/chat_history.csv")
def download_history_csv():
    if not CHAT_CSV.exists():
        return JSONResponse({"detail": "chat_history.csv not found"}, status_code=404)
    return FileResponse(CHAT_CSV, media_type="text/csv", filename="chat_history.csv")

@app.get("/feedback.csv")
def download_feedback_csv():
    if not FEED_CSV.exists():
        return JSONResponse({"detail": "feedback.csv not found"}, status_code=404)
    return FileResponse(FEED_CSV, media_type="text/csv", filename="feedback.csv")

# -------------------------
# 10) (Tu·ª≥ ch·ªçn) Endpoint n·∫°p l·∫°i KB khi thay MC_chatbot.csv
# -------------------------
@app.post("/reload_kb")
def reload_kb():
    """ƒê·ªçc l·∫°i MC_chatbot.csv & t√°i t·∫°o FAISS m√† kh√¥ng c·∫ßn redeploy."""
    global questions, answers, embeddings, index
    q, a = _load_kb(KB_CSV)
    if not q:
        return JSONResponse({"detail": "MC_chatbot.csv missing or invalid"}, status_code=400)

    questions, answers = q, a
    embeddings = model.encode(questions, convert_to_numpy=True)
    index = faiss.IndexFlatL2(embeddings.shape[1])
    index.add(embeddings)
    return {"status": "ok", "count": len(questions)}
